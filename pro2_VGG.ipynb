{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as trans\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(1)\n",
    "torch.set_default_tensor_type('torch.cuda.DoubleTensor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = dsets.CIFAR10(root = './CIFAR10/',\n",
    "                        train = True,\n",
    "                        transform = trans.ToTensor(),\n",
    "                        download = False)\n",
    "\n",
    "test_set = dsets.CIFAR10(root = './CIFAR10/',\n",
    "                       train = False,\n",
    "                       transform = trans.ToTensor(),\n",
    "                       download = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_inputs = []\n",
    "list_label = []\n",
    "for i, data in enumerate(train_set, 0):\n",
    "    inputs, label = data\n",
    "    if label == 0:\n",
    "        list_inputs.append(inputs.tolist())\n",
    "        list_label.append(0)\n",
    "    elif label == 1:\n",
    "        list_inputs.append(inputs.tolist())\n",
    "        list_label.append(1)\n",
    "        \n",
    "A = torch.tensor(list_inputs[0:1000]).cuda()\n",
    "B = torch.tensor(list_label[0:1000]).cuda()\n",
    "train_set = TensorDataset(A, B)\n",
    "\n",
    "list_inputs = []\n",
    "list_label = []\n",
    "for i, data in enumerate(test_set, 0):\n",
    "    inputs, label = data\n",
    "    if label == 0:\n",
    "        list_inputs.append(inputs.tolist())\n",
    "        list_label.append(0)\n",
    "    elif label == 1:\n",
    "        list_inputs.append(inputs.tolist())\n",
    "        list_label.append(1)\n",
    "C = torch.tensor(list_inputs[0:1000]).cuda()\n",
    "D = torch.tensor(list_label[0:1000]).cuda()\n",
    "test_set = TensorDataset(C, D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_set,\n",
    "                     batch_size = 50,\n",
    "                     num_workers = 0)\n",
    "\n",
    "test_dl = DataLoader(test_set,\n",
    "                    batch_size = 100,\n",
    "                    num_workers = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VGG, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size = 3, padding = 1)\n",
    "        self.pool1 = nn.AvgPool2d(2)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size = 3, padding = 1)\n",
    "        self.pool2 = nn.AvgPool2d(2)\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size = 3, padding = 1)\n",
    "        self.pool3 = nn.AvgPool2d(2)\n",
    "        self.conv4 = nn.Conv2d(64, 64, kernel_size = 3, padding = 1)\n",
    "        self.pool4 = nn.AvgPool2d(2)\n",
    "        self.fc1 = nn.Linear(2*2*64, 128)\n",
    "        self.fc2 = nn.Linear(128, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        o = self.conv1(x)\n",
    "        o = self.pool1(o)\n",
    "        o = F.relu(o)\n",
    "        \n",
    "        o = self.conv2(o)\n",
    "        o = self.pool2(o)\n",
    "        o = F.relu(o)\n",
    "        \n",
    "        o = self.conv3(o)\n",
    "        o = self.pool3(o)\n",
    "        o = F.relu(o)\n",
    "        \n",
    "        o = self.conv4(o)\n",
    "        o = self.pool4(o)\n",
    "        o = F.relu(o)\n",
    "        \n",
    "        # Flat \n",
    "        o = o.view(x.size(0),-1)\n",
    "        \n",
    "        o = self.fc1(o)\n",
    "        o = F.relu(o)\n",
    "        \n",
    "        o = self.fc2(o)\n",
    "        return o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, optimizer, criterion, dataloader):\n",
    "    loss_tot, nbatch = 0, 0\n",
    "    for batch_x, batch_y in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        o = model(batch_x)\n",
    "        loss = criterion(o, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_tot += loss.item()\n",
    "        nbatch += 1\n",
    "    return loss_tot / nbatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_accuracy(model, dataloader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_x, batch_y in dataloader:\n",
    "            batch_o = model(batch_x)\n",
    "            pred = batch_o.max(1, keepdim = True)[1]\n",
    "            correct += pred.eq(batch_y.view_as(pred)).float().mean().item()\n",
    "    return correct * 100.0 / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = VGG().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(net.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/300, tr_loss 6.84e-01, tr_acc 71.90\n",
      "2/300, tr_loss 5.94e-01, tr_acc 73.30\n",
      "3/300, tr_loss 5.92e-01, tr_acc 70.50\n",
      "4/300, tr_loss 5.61e-01, tr_acc 73.90\n",
      "5/300, tr_loss 5.37e-01, tr_acc 74.70\n",
      "6/300, tr_loss 5.25e-01, tr_acc 75.70\n",
      "7/300, tr_loss 5.06e-01, tr_acc 78.50\n",
      "8/300, tr_loss 4.88e-01, tr_acc 79.40\n",
      "9/300, tr_loss 4.65e-01, tr_acc 80.80\n",
      "10/300, tr_loss 4.46e-01, tr_acc 82.30\n",
      "11/300, tr_loss 4.16e-01, tr_acc 83.20\n",
      "12/300, tr_loss 3.96e-01, tr_acc 83.80\n",
      "13/300, tr_loss 3.79e-01, tr_acc 84.10\n",
      "14/300, tr_loss 3.73e-01, tr_acc 85.80\n",
      "15/300, tr_loss 3.65e-01, tr_acc 86.30\n",
      "16/300, tr_loss 3.48e-01, tr_acc 86.60\n",
      "17/300, tr_loss 3.39e-01, tr_acc 86.70\n",
      "18/300, tr_loss 3.30e-01, tr_acc 87.90\n",
      "19/300, tr_loss 3.24e-01, tr_acc 88.40\n",
      "20/300, tr_loss 3.21e-01, tr_acc 87.90\n",
      "21/300, tr_loss 3.11e-01, tr_acc 87.70\n",
      "22/300, tr_loss 2.95e-01, tr_acc 89.20\n",
      "23/300, tr_loss 2.83e-01, tr_acc 89.20\n",
      "24/300, tr_loss 2.75e-01, tr_acc 89.70\n",
      "25/300, tr_loss 2.66e-01, tr_acc 90.20\n",
      "26/300, tr_loss 2.63e-01, tr_acc 89.60\n",
      "27/300, tr_loss 2.61e-01, tr_acc 89.40\n",
      "28/300, tr_loss 2.59e-01, tr_acc 90.50\n",
      "29/300, tr_loss 2.59e-01, tr_acc 90.70\n",
      "30/300, tr_loss 2.64e-01, tr_acc 90.80\n",
      "31/300, tr_loss 2.68e-01, tr_acc 88.60\n",
      "32/300, tr_loss 2.49e-01, tr_acc 90.70\n",
      "33/300, tr_loss 2.29e-01, tr_acc 92.10\n",
      "34/300, tr_loss 2.22e-01, tr_acc 92.20\n",
      "35/300, tr_loss 2.16e-01, tr_acc 92.40\n",
      "36/300, tr_loss 2.11e-01, tr_acc 92.40\n",
      "37/300, tr_loss 2.10e-01, tr_acc 92.90\n",
      "38/300, tr_loss 2.08e-01, tr_acc 91.00\n",
      "39/300, tr_loss 2.04e-01, tr_acc 91.10\n",
      "40/300, tr_loss 1.91e-01, tr_acc 92.60\n",
      "41/300, tr_loss 1.85e-01, tr_acc 93.70\n",
      "42/300, tr_loss 1.76e-01, tr_acc 94.10\n",
      "43/300, tr_loss 1.67e-01, tr_acc 93.90\n",
      "44/300, tr_loss 1.61e-01, tr_acc 93.80\n",
      "45/300, tr_loss 1.53e-01, tr_acc 94.10\n",
      "46/300, tr_loss 1.45e-01, tr_acc 94.50\n",
      "47/300, tr_loss 1.41e-01, tr_acc 95.00\n",
      "48/300, tr_loss 1.36e-01, tr_acc 95.50\n",
      "49/300, tr_loss 1.38e-01, tr_acc 95.40\n",
      "50/300, tr_loss 1.35e-01, tr_acc 93.30\n",
      "51/300, tr_loss 1.63e-01, tr_acc 92.30\n",
      "52/300, tr_loss 1.57e-01, tr_acc 94.70\n",
      "53/300, tr_loss 1.56e-01, tr_acc 96.00\n",
      "54/300, tr_loss 1.49e-01, tr_acc 94.40\n",
      "55/300, tr_loss 1.34e-01, tr_acc 93.40\n",
      "56/300, tr_loss 1.03e-01, tr_acc 96.60\n",
      "57/300, tr_loss 1.00e-01, tr_acc 97.70\n",
      "58/300, tr_loss 8.11e-02, tr_acc 96.70\n",
      "59/300, tr_loss 6.95e-02, tr_acc 97.60\n",
      "60/300, tr_loss 6.63e-02, tr_acc 97.20\n",
      "61/300, tr_loss 7.14e-02, tr_acc 95.90\n",
      "62/300, tr_loss 7.16e-02, tr_acc 95.80\n",
      "63/300, tr_loss 6.21e-02, tr_acc 98.60\n",
      "64/300, tr_loss 5.14e-02, tr_acc 98.50\n",
      "65/300, tr_loss 4.44e-02, tr_acc 98.80\n",
      "66/300, tr_loss 4.14e-02, tr_acc 96.30\n",
      "67/300, tr_loss 5.58e-02, tr_acc 98.30\n",
      "68/300, tr_loss 6.36e-02, tr_acc 96.50\n",
      "69/300, tr_loss 4.67e-02, tr_acc 95.70\n",
      "70/300, tr_loss 4.59e-02, tr_acc 98.60\n",
      "71/300, tr_loss 3.71e-02, tr_acc 99.10\n",
      "72/300, tr_loss 4.59e-02, tr_acc 99.10\n",
      "73/300, tr_loss 5.02e-02, tr_acc 97.40\n",
      "74/300, tr_loss 8.77e-02, tr_acc 98.50\n",
      "75/300, tr_loss 8.20e-02, tr_acc 95.10\n",
      "76/300, tr_loss 8.07e-02, tr_acc 96.90\n",
      "77/300, tr_loss 3.94e-02, tr_acc 99.60\n",
      "78/300, tr_loss 2.15e-02, tr_acc 97.10\n",
      "79/300, tr_loss 2.05e-02, tr_acc 98.90\n",
      "80/300, tr_loss 1.55e-02, tr_acc 99.10\n",
      "81/300, tr_loss 1.48e-02, tr_acc 99.40\n",
      "82/300, tr_loss 1.57e-02, tr_acc 96.70\n",
      "83/300, tr_loss 3.43e-02, tr_acc 97.90\n",
      "84/300, tr_loss 2.01e-02, tr_acc 96.90\n",
      "85/300, tr_loss 2.29e-02, tr_acc 98.60\n",
      "86/300, tr_loss 2.84e-02, tr_acc 98.50\n",
      "87/300, tr_loss 2.75e-02, tr_acc 99.50\n",
      "88/300, tr_loss 2.44e-02, tr_acc 98.20\n",
      "89/300, tr_loss 2.30e-02, tr_acc 97.70\n",
      "90/300, tr_loss 1.63e-02, tr_acc 98.90\n",
      "91/300, tr_loss 1.95e-02, tr_acc 98.70\n",
      "92/300, tr_loss 1.83e-02, tr_acc 99.60\n",
      "93/300, tr_loss 1.75e-02, tr_acc 99.60\n",
      "94/300, tr_loss 2.16e-02, tr_acc 97.60\n",
      "95/300, tr_loss 3.17e-02, tr_acc 93.10\n",
      "96/300, tr_loss 8.11e-02, tr_acc 96.70\n",
      "97/300, tr_loss 4.25e-02, tr_acc 99.30\n",
      "98/300, tr_loss 2.38e-02, tr_acc 98.10\n",
      "99/300, tr_loss 1.70e-02, tr_acc 99.30\n",
      "100/300, tr_loss 1.77e-02, tr_acc 99.90\n",
      "101/300, tr_loss 2.86e-02, tr_acc 99.20\n",
      "102/300, tr_loss 3.62e-02, tr_acc 97.00\n",
      "103/300, tr_loss 2.74e-02, tr_acc 99.30\n",
      "104/300, tr_loss 3.71e-02, tr_acc 99.10\n",
      "105/300, tr_loss 3.65e-02, tr_acc 99.40\n",
      "106/300, tr_loss 3.75e-02, tr_acc 99.60\n",
      "107/300, tr_loss 4.01e-02, tr_acc 98.50\n",
      "108/300, tr_loss 5.94e-02, tr_acc 99.40\n",
      "109/300, tr_loss 4.15e-02, tr_acc 99.00\n",
      "110/300, tr_loss 2.20e-02, tr_acc 98.90\n",
      "111/300, tr_loss 2.62e-02, tr_acc 99.90\n",
      "112/300, tr_loss 1.79e-02, tr_acc 99.80\n",
      "113/300, tr_loss 1.32e-02, tr_acc 99.80\n",
      "114/300, tr_loss 3.94e-03, tr_acc 100.00\n",
      "115/300, tr_loss 1.23e-03, tr_acc 100.00\n",
      "116/300, tr_loss 8.40e-04, tr_acc 100.00\n",
      "117/300, tr_loss 6.73e-04, tr_acc 100.00\n",
      "118/300, tr_loss 5.98e-04, tr_acc 100.00\n",
      "119/300, tr_loss 5.42e-04, tr_acc 100.00\n",
      "120/300, tr_loss 4.99e-04, tr_acc 100.00\n",
      "121/300, tr_loss 4.65e-04, tr_acc 100.00\n",
      "122/300, tr_loss 4.35e-04, tr_acc 100.00\n",
      "123/300, tr_loss 4.10e-04, tr_acc 100.00\n",
      "124/300, tr_loss 3.87e-04, tr_acc 100.00\n",
      "125/300, tr_loss 3.67e-04, tr_acc 100.00\n",
      "126/300, tr_loss 3.49e-04, tr_acc 100.00\n",
      "127/300, tr_loss 3.33e-04, tr_acc 100.00\n",
      "128/300, tr_loss 3.18e-04, tr_acc 100.00\n",
      "129/300, tr_loss 3.04e-04, tr_acc 100.00\n",
      "130/300, tr_loss 2.91e-04, tr_acc 100.00\n",
      "131/300, tr_loss 2.80e-04, tr_acc 100.00\n",
      "132/300, tr_loss 2.69e-04, tr_acc 100.00\n",
      "133/300, tr_loss 2.59e-04, tr_acc 100.00\n",
      "134/300, tr_loss 2.49e-04, tr_acc 100.00\n",
      "135/300, tr_loss 2.40e-04, tr_acc 100.00\n",
      "136/300, tr_loss 2.32e-04, tr_acc 100.00\n",
      "137/300, tr_loss 2.24e-04, tr_acc 100.00\n",
      "138/300, tr_loss 2.16e-04, tr_acc 100.00\n",
      "139/300, tr_loss 2.09e-04, tr_acc 100.00\n",
      "140/300, tr_loss 2.03e-04, tr_acc 100.00\n",
      "141/300, tr_loss 1.96e-04, tr_acc 100.00\n",
      "142/300, tr_loss 1.90e-04, tr_acc 100.00\n",
      "143/300, tr_loss 1.85e-04, tr_acc 100.00\n",
      "144/300, tr_loss 1.79e-04, tr_acc 100.00\n",
      "145/300, tr_loss 1.74e-04, tr_acc 100.00\n",
      "146/300, tr_loss 1.69e-04, tr_acc 100.00\n",
      "147/300, tr_loss 1.64e-04, tr_acc 100.00\n",
      "148/300, tr_loss 1.59e-04, tr_acc 100.00\n",
      "149/300, tr_loss 1.55e-04, tr_acc 100.00\n",
      "150/300, tr_loss 1.51e-04, tr_acc 100.00\n",
      "151/300, tr_loss 1.47e-04, tr_acc 100.00\n",
      "152/300, tr_loss 1.43e-04, tr_acc 100.00\n",
      "153/300, tr_loss 1.40e-04, tr_acc 100.00\n",
      "154/300, tr_loss 1.36e-04, tr_acc 100.00\n",
      "155/300, tr_loss 1.33e-04, tr_acc 100.00\n",
      "156/300, tr_loss 1.30e-04, tr_acc 100.00\n",
      "157/300, tr_loss 1.27e-04, tr_acc 100.00\n",
      "158/300, tr_loss 1.24e-04, tr_acc 100.00\n",
      "159/300, tr_loss 1.21e-04, tr_acc 100.00\n",
      "160/300, tr_loss 1.18e-04, tr_acc 100.00\n",
      "161/300, tr_loss 1.15e-04, tr_acc 100.00\n",
      "162/300, tr_loss 1.12e-04, tr_acc 100.00\n",
      "163/300, tr_loss 1.10e-04, tr_acc 100.00\n",
      "164/300, tr_loss 1.07e-04, tr_acc 100.00\n",
      "165/300, tr_loss 1.05e-04, tr_acc 100.00\n",
      "166/300, tr_loss 1.03e-04, tr_acc 100.00\n",
      "167/300, tr_loss 1.01e-04, tr_acc 100.00\n",
      "168/300, tr_loss 9.86e-05, tr_acc 100.00\n",
      "169/300, tr_loss 9.65e-05, tr_acc 100.00\n",
      "170/300, tr_loss 9.45e-05, tr_acc 100.00\n",
      "171/300, tr_loss 9.26e-05, tr_acc 100.00\n",
      "172/300, tr_loss 9.07e-05, tr_acc 100.00\n",
      "173/300, tr_loss 8.89e-05, tr_acc 100.00\n",
      "174/300, tr_loss 8.71e-05, tr_acc 100.00\n",
      "175/300, tr_loss 8.54e-05, tr_acc 100.00\n",
      "176/300, tr_loss 8.37e-05, tr_acc 100.00\n",
      "177/300, tr_loss 8.21e-05, tr_acc 100.00\n",
      "178/300, tr_loss 8.05e-05, tr_acc 100.00\n",
      "179/300, tr_loss 7.90e-05, tr_acc 100.00\n",
      "180/300, tr_loss 7.75e-05, tr_acc 100.00\n",
      "181/300, tr_loss 7.60e-05, tr_acc 100.00\n",
      "182/300, tr_loss 7.46e-05, tr_acc 100.00\n",
      "183/300, tr_loss 7.33e-05, tr_acc 100.00\n",
      "184/300, tr_loss 7.19e-05, tr_acc 100.00\n",
      "185/300, tr_loss 7.06e-05, tr_acc 100.00\n",
      "186/300, tr_loss 6.94e-05, tr_acc 100.00\n",
      "187/300, tr_loss 6.81e-05, tr_acc 100.00\n",
      "188/300, tr_loss 6.69e-05, tr_acc 100.00\n",
      "189/300, tr_loss 6.57e-05, tr_acc 100.00\n",
      "190/300, tr_loss 6.46e-05, tr_acc 100.00\n",
      "191/300, tr_loss 6.35e-05, tr_acc 100.00\n",
      "192/300, tr_loss 6.24e-05, tr_acc 100.00\n",
      "193/300, tr_loss 6.13e-05, tr_acc 100.00\n",
      "194/300, tr_loss 6.03e-05, tr_acc 100.00\n",
      "195/300, tr_loss 5.92e-05, tr_acc 100.00\n",
      "196/300, tr_loss 5.82e-05, tr_acc 100.00\n",
      "197/300, tr_loss 5.73e-05, tr_acc 100.00\n",
      "198/300, tr_loss 5.63e-05, tr_acc 100.00\n",
      "199/300, tr_loss 5.54e-05, tr_acc 100.00\n",
      "200/300, tr_loss 5.45e-05, tr_acc 100.00\n",
      "201/300, tr_loss 5.36e-05, tr_acc 100.00\n",
      "202/300, tr_loss 5.27e-05, tr_acc 100.00\n",
      "203/300, tr_loss 5.19e-05, tr_acc 100.00\n",
      "204/300, tr_loss 5.10e-05, tr_acc 100.00\n",
      "205/300, tr_loss 5.02e-05, tr_acc 100.00\n",
      "206/300, tr_loss 4.94e-05, tr_acc 100.00\n",
      "207/300, tr_loss 4.86e-05, tr_acc 100.00\n",
      "208/300, tr_loss 4.78e-05, tr_acc 100.00\n",
      "209/300, tr_loss 4.71e-05, tr_acc 100.00\n",
      "210/300, tr_loss 4.63e-05, tr_acc 100.00\n",
      "211/300, tr_loss 4.56e-05, tr_acc 100.00\n",
      "212/300, tr_loss 4.49e-05, tr_acc 100.00\n",
      "213/300, tr_loss 4.42e-05, tr_acc 100.00\n",
      "214/300, tr_loss 4.35e-05, tr_acc 100.00\n",
      "215/300, tr_loss 4.29e-05, tr_acc 100.00\n",
      "216/300, tr_loss 4.22e-05, tr_acc 100.00\n",
      "217/300, tr_loss 4.16e-05, tr_acc 100.00\n",
      "218/300, tr_loss 4.10e-05, tr_acc 100.00\n",
      "219/300, tr_loss 4.04e-05, tr_acc 100.00\n",
      "220/300, tr_loss 3.98e-05, tr_acc 100.00\n",
      "221/300, tr_loss 3.92e-05, tr_acc 100.00\n",
      "222/300, tr_loss 3.86e-05, tr_acc 100.00\n",
      "223/300, tr_loss 3.81e-05, tr_acc 100.00\n",
      "224/300, tr_loss 3.75e-05, tr_acc 100.00\n",
      "225/300, tr_loss 3.70e-05, tr_acc 100.00\n",
      "226/300, tr_loss 3.64e-05, tr_acc 100.00\n",
      "227/300, tr_loss 3.59e-05, tr_acc 100.00\n",
      "228/300, tr_loss 3.54e-05, tr_acc 100.00\n",
      "229/300, tr_loss 3.49e-05, tr_acc 100.00\n",
      "230/300, tr_loss 3.44e-05, tr_acc 100.00\n",
      "231/300, tr_loss 3.39e-05, tr_acc 100.00\n",
      "232/300, tr_loss 3.34e-05, tr_acc 100.00\n",
      "233/300, tr_loss 3.29e-05, tr_acc 100.00\n",
      "234/300, tr_loss 3.25e-05, tr_acc 100.00\n",
      "235/300, tr_loss 3.20e-05, tr_acc 100.00\n",
      "236/300, tr_loss 3.16e-05, tr_acc 100.00\n",
      "237/300, tr_loss 3.12e-05, tr_acc 100.00\n",
      "238/300, tr_loss 3.07e-05, tr_acc 100.00\n",
      "239/300, tr_loss 3.03e-05, tr_acc 100.00\n",
      "240/300, tr_loss 2.99e-05, tr_acc 100.00\n",
      "241/300, tr_loss 2.95e-05, tr_acc 100.00\n",
      "242/300, tr_loss 2.91e-05, tr_acc 100.00\n",
      "243/300, tr_loss 2.87e-05, tr_acc 100.00\n",
      "244/300, tr_loss 2.83e-05, tr_acc 100.00\n",
      "245/300, tr_loss 2.79e-05, tr_acc 100.00\n",
      "246/300, tr_loss 2.76e-05, tr_acc 100.00\n",
      "247/300, tr_loss 2.72e-05, tr_acc 100.00\n",
      "248/300, tr_loss 2.68e-05, tr_acc 100.00\n",
      "249/300, tr_loss 2.65e-05, tr_acc 100.00\n",
      "250/300, tr_loss 2.61e-05, tr_acc 100.00\n",
      "251/300, tr_loss 2.58e-05, tr_acc 100.00\n",
      "252/300, tr_loss 2.54e-05, tr_acc 100.00\n",
      "253/300, tr_loss 2.51e-05, tr_acc 100.00\n",
      "254/300, tr_loss 2.48e-05, tr_acc 100.00\n",
      "255/300, tr_loss 2.45e-05, tr_acc 100.00\n",
      "256/300, tr_loss 2.41e-05, tr_acc 100.00\n",
      "257/300, tr_loss 2.38e-05, tr_acc 100.00\n",
      "258/300, tr_loss 2.35e-05, tr_acc 100.00\n",
      "259/300, tr_loss 2.32e-05, tr_acc 100.00\n",
      "260/300, tr_loss 2.29e-05, tr_acc 100.00\n",
      "261/300, tr_loss 2.26e-05, tr_acc 100.00\n",
      "262/300, tr_loss 2.24e-05, tr_acc 100.00\n",
      "263/300, tr_loss 2.21e-05, tr_acc 100.00\n",
      "264/300, tr_loss 2.18e-05, tr_acc 100.00\n",
      "265/300, tr_loss 2.15e-05, tr_acc 100.00\n",
      "266/300, tr_loss 2.12e-05, tr_acc 100.00\n",
      "267/300, tr_loss 2.10e-05, tr_acc 100.00\n",
      "268/300, tr_loss 2.07e-05, tr_acc 100.00\n",
      "269/300, tr_loss 2.05e-05, tr_acc 100.00\n",
      "270/300, tr_loss 2.02e-05, tr_acc 100.00\n",
      "271/300, tr_loss 1.99e-05, tr_acc 100.00\n",
      "272/300, tr_loss 1.97e-05, tr_acc 100.00\n",
      "273/300, tr_loss 1.95e-05, tr_acc 100.00\n",
      "274/300, tr_loss 1.92e-05, tr_acc 100.00\n",
      "275/300, tr_loss 1.90e-05, tr_acc 100.00\n",
      "276/300, tr_loss 1.87e-05, tr_acc 100.00\n",
      "277/300, tr_loss 1.85e-05, tr_acc 100.00\n",
      "278/300, tr_loss 1.83e-05, tr_acc 100.00\n",
      "279/300, tr_loss 1.80e-05, tr_acc 100.00\n",
      "280/300, tr_loss 1.78e-05, tr_acc 100.00\n",
      "281/300, tr_loss 1.76e-05, tr_acc 100.00\n",
      "282/300, tr_loss 1.74e-05, tr_acc 100.00\n",
      "283/300, tr_loss 1.72e-05, tr_acc 100.00\n",
      "284/300, tr_loss 1.70e-05, tr_acc 100.00\n",
      "285/300, tr_loss 1.68e-05, tr_acc 100.00\n",
      "286/300, tr_loss 1.65e-05, tr_acc 100.00\n",
      "287/300, tr_loss 1.63e-05, tr_acc 100.00\n",
      "288/300, tr_loss 1.61e-05, tr_acc 100.00\n",
      "289/300, tr_loss 1.59e-05, tr_acc 100.00\n",
      "290/300, tr_loss 1.57e-05, tr_acc 100.00\n",
      "291/300, tr_loss 1.56e-05, tr_acc 100.00\n",
      "292/300, tr_loss 1.54e-05, tr_acc 100.00\n",
      "293/300, tr_loss 1.52e-05, tr_acc 100.00\n",
      "294/300, tr_loss 1.50e-05, tr_acc 100.00\n",
      "295/300, tr_loss 1.48e-05, tr_acc 100.00\n",
      "296/300, tr_loss 1.46e-05, tr_acc 100.00\n",
      "297/300, tr_loss 1.44e-05, tr_acc 100.00\n",
      "298/300, tr_loss 1.43e-05, tr_acc 100.00\n",
      "299/300, tr_loss 1.41e-05, tr_acc 100.00\n",
      "300/300, tr_loss 1.39e-05, tr_acc 100.00\n"
     ]
    }
   ],
   "source": [
    "nepochs = 300\n",
    "for epoch in range(nepochs):\n",
    "    train_loss = train_epoch(net, optimizer, criterion, train_dl)\n",
    "    train_acc = eval_accuracy(net, train_dl)\n",
    "    print('{:}/{:}, tr_loss {:.2e}, tr_acc {:.2f}'.format(epoch + 1, nepochs, train_loss, train_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89.59999740123749"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_accuracy(net, test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
